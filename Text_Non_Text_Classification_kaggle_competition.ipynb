{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text - Non Text Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Urstruelycharan/GUVI-DeepLearning/blob/master/Text_Non_Text_Classification_kaggle_competition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a192xmwKijHs",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageFilter\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(100)\n",
        "LEVEL = 'level_1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIuRdSezijHx",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "class SigmoidNeuron:\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.w = None\n",
        "    self.b = None\n",
        "    \n",
        "  def perceptron(self, x):\n",
        "    return np.dot(x, self.w.T) + self.b\n",
        "  \n",
        "  def sigmoid(self, x):\n",
        "    return 1.0/(1.0 + np.exp(-x))\n",
        "  \n",
        "  def grad_w_mse(self, x, y):\n",
        "    y_pred = self.sigmoid(self.perceptron(x))\n",
        "    return (y_pred - y) * y_pred * (1 - y_pred) * x\n",
        "  \n",
        "  def grad_b_mse(self, x, y):\n",
        "    y_pred = self.sigmoid(self.perceptron(x))\n",
        "    return (y_pred - y) * y_pred * (1 - y_pred)\n",
        "  \n",
        "  def grad_w_ce(self, x, y):\n",
        "    y_pred = self.sigmoid(self.perceptron(x))\n",
        "    if y == 0:\n",
        "      return y_pred * x\n",
        "    elif y == 1:\n",
        "      return -1 * (1 - y_pred) * x\n",
        "    else:\n",
        "      raise ValueError(\"y should be 0 or 1\")\n",
        "    \n",
        "  def grad_b_ce(self, x, y):\n",
        "    y_pred = self.sigmoid(self.perceptron(x))\n",
        "    if y == 0:\n",
        "      return y_pred \n",
        "    elif y == 1:\n",
        "      return -1 * (1 - y_pred)\n",
        "    else:\n",
        "      raise ValueError(\"y should be 0 or 1\")\n",
        "  \n",
        "  def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, loss_fn=\"mse\", display_loss=False):\n",
        "    \n",
        "    # initialise w, b\n",
        "    if initialise:\n",
        "      self.w = np.random.randn(1, X.shape[1])\n",
        "      self.b = 0\n",
        "      \n",
        "    if display_loss:\n",
        "      loss = {}\n",
        "    \n",
        "    for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n",
        "      dw = 0\n",
        "      db = 0\n",
        "      for x, y in zip(X, Y):\n",
        "        if loss_fn == \"mse\":\n",
        "          dw += self.grad_w_mse(x, y)\n",
        "          db += self.grad_b_mse(x, y) \n",
        "        elif loss_fn == \"ce\":\n",
        "          dw += self.grad_w_ce(x, y)\n",
        "          db += self.grad_b_ce(x, y)\n",
        "      self.w -= learning_rate * dw\n",
        "      self.b -= learning_rate * db\n",
        "      \n",
        "      if display_loss:\n",
        "        Y_pred = self.sigmoid(self.perceptron(X))\n",
        "        if loss_fn == \"mse\":\n",
        "          loss[i] = mean_squared_error(Y, Y_pred)\n",
        "        elif loss_fn == \"ce\":\n",
        "          loss[i] = log_loss(Y, Y_pred)\n",
        "    \n",
        "    if display_loss:\n",
        "      plt.plot(loss.values())\n",
        "      plt.xlabel('Epochs')\n",
        "      if loss_fn == \"mse\":\n",
        "        plt.ylabel('Mean Squared Error')\n",
        "      elif loss_fn == \"ce\":\n",
        "        plt.ylabel('Log Loss')\n",
        "      plt.show()\n",
        "      \n",
        "  def predict(self, X):\n",
        "    Y_pred = []\n",
        "    for x in X:\n",
        "      y_pred = self.sigmoid(self.perceptron(x))\n",
        "      Y_pred.append(y_pred)\n",
        "    return np.array(Y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDe2wjl_ijH0",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def read_all(folder_path, key_prefix=\"\"):\n",
        "    '''\n",
        "    It returns a dictionary with 'file names' as keys and 'flattened image arrays' as values.\n",
        "    '''\n",
        "    print(\"Reading:\")\n",
        "    images = {}\n",
        "    files = os.listdir(folder_path)\n",
        "    for i, file_name in tqdm_notebook(enumerate(files), total=len(files)):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        image_index = key_prefix + file_name[:-4]\n",
        "        image = Image.open(file_path)\n",
        "        image = image.convert(\"L\")\n",
        "        images[image_index] = np.array(image.copy()).flatten()\n",
        "        image.close()\n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjuaN532ijH4",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "languages = ['ta', 'hi', 'en']\n",
        "trainPath = \"../input/padhai-text-non-text-classification-level-1/\"+LEVEL+\"_train/\"+LEVEL+\"/\"\n",
        "testPath = \"../input/padhai-text-non-text-classification-level-1/\"+LEVEL+\"_test/kaggle_\"+LEVEL\n",
        "images_train = read_all(path+\"background\", key_prefix='bgr_') # change the path\n",
        "for language in languages:\n",
        "  images_train.update(read_all(path+language, key_prefix=language+\"_\" ))\n",
        "print(len(images_train))\n",
        "\n",
        "images_test = read_all(testPath, key_prefix='') # change the path\n",
        "print(len(images_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J484_NefjCLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cd ../input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqcTJRmSijH-",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "list(images_test.keys())[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQUKxV_FijIC",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "for key, value in images_train.items():\n",
        "    X_train.append(value)\n",
        "    if key[:4] == \"bgr_\":\n",
        "        Y_train.append(0)\n",
        "    else:\n",
        "        Y_train.append(1)\n",
        "\n",
        "ID_test = []\n",
        "X_test = []\n",
        "for key, value in images_test.items():\n",
        "  ID_test.append(int(key))\n",
        "  X_test.append(value)\n",
        "  \n",
        "        \n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy3IKx26ijIG",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled_train = scaler.fit_transform(X_train)\n",
        "X_scaled_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eboQW2n1ijIK",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "sn_mse = SigmoidNeuron()\n",
        "sn_mse.fit(X_scaled_train, Y_train, epochs=100, learning_rate=0.015, loss_fn=\"mse\", display_loss=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "547SFsgsijIO",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "sn_ce = SigmoidNeuron()\n",
        "sn_ce.fit(X_scaled_train, Y_train, epochs=100, learning_rate=0.015, loss_fn=\"ce\", display_loss=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a3_-9zYijIS",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def print_accuracy(sn):\n",
        "  Y_pred_train = sn.predict(X_scaled_train)\n",
        "  Y_pred_binarised_train = (Y_pred_train >= 0.5).astype(\"int\").ravel()\n",
        "  accuracy_train = accuracy_score(Y_pred_binarised_train, Y_train)\n",
        "  print(\"Train Accuracy : \", accuracy_train)\n",
        "  print(\"-\"*50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqe2g9PLijIW",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "print_accuracy(sn_mse)\n",
        "print_accuracy(sn_ce)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IMv7SCUijIa",
        "colab_type": "text"
      },
      "source": [
        "## Sample Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_pBsgYlijIb",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "Y_pred_test = sn_ce.predict(X_scaled_test)\n",
        "Y_pred_binarised_test = (Y_pred_test >= 0.5).astype(\"int\").ravel()\n",
        "\n",
        "submission = {}\n",
        "submission['ImageId'] = ID_test\n",
        "submission['Class'] = Y_pred_binarised_test\n",
        "\n",
        "submission = pd.DataFrame(submission)\n",
        "submission = submission[['ImageId', 'Class']]\n",
        "submission = submission.sort_values(['ImageId'])\n",
        "submission.to_csv(\"submisision.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}